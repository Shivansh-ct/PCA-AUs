{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import AffineTransform, SimilarityTransform\n",
    "# import math\n",
    "import numpy as np\n",
    "# from helper import DataLoader, Transform\n",
    "# import matplotlib.pyplot as plt\n",
    "# from skimage import data\n",
    "# from skimage import transform as tf\n",
    "# import json\n",
    "# import cv2\n",
    "from itertools import groupby\n",
    "import glob\n",
    "import pandas as pd\n",
    "# from math import ceil\n",
    "import os\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_trans(kp, data_name=None, matrix=None):\n",
    "    src = np.float32([kp[0], kp[16], kp[27], kp[33], kp[39], kp[42]])\n",
    "    dst = np.float32([[300,900], [1100, 900], [700, 900], [700, 1300],[600,1000],[800,1000]])\n",
    "    \n",
    "    if data_name==\"bp4d\":\n",
    "        src = np.float32([kp[27], kp[33], kp[39], kp[42], kp[36], kp[45]])\n",
    "        dst = np.float32([[700, 900], [700, 1300],[600,1000],[800,1000], [400, 1000], [1000, 1000]])\n",
    "\n",
    "    src_h = np.concatenate((src.T, np.ones(src.shape[0]).reshape(1,src.shape[0])), axis=0)\n",
    "    dst_h = np.concatenate((dst.T, np.ones(dst.shape[0]).reshape(1,dst.shape[0])), axis=0)\n",
    "    \n",
    "    kp_h = np.concatenate((kp.T, np.ones(kp.shape[0]).reshape(1,kp.shape[0])), axis=0)\n",
    "    \n",
    "    if matrix is None: matrix = dst_h@np.linalg.pinv(src_h)\n",
    "    kp_h = matrix@kp_h\n",
    "    \n",
    "    return matrix, kp_h[:2, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SimilarityTransform(matrix=\n",
      "    [[ 1.33333328e+01,  2.66666656e+01,  2.93333342e+02],\n",
      "     [-2.66666656e+01,  1.33333328e+01,  1.01333333e+03],\n",
      "     [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])>\n",
      "<SimilarityTransform(matrix=\n",
      "    [[nan, nan, nan],\n",
      "     [nan, nan, nan],\n",
      "     [nan, nan, nan]])>\n"
     ]
    }
   ],
   "source": [
    "# just for demo\n",
    "\n",
    "src = np.float32([[2,3], [5,9]])\n",
    "dst = np.float32([[400,1000], [600,1000]])\n",
    "tform = SimilarityTransform()\n",
    "tform.estimate(src, dst)\n",
    "print(tform)\n",
    "\n",
    "src = np.float32([[2,3]])\n",
    "dst = np.float32([[600,1000]])\n",
    "tform = SimilarityTransform()\n",
    "tform.estimate(src, dst)\n",
    "print(tform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_trans(kp, matrix=None): \n",
    "    \n",
    "    # Registering right eyebrow and eyes\n",
    "    src = kp[[36,39], :]\n",
    "    dst = np.float32([[400, 1000], [600, 1000]])\n",
    "    tform = SimilarityTransform()\n",
    "    tform.estimate(src, dst)\n",
    "    kp[17:22, :] = tform(kp[17:22, :])\n",
    "    kp[36:42, :] = tform(kp[36:42, :])  \n",
    "    \n",
    "    # Registering left eyebrow and eyes\n",
    "    src = kp[[42,45], :]\n",
    "    dst = np.float32([[800, 1000], [1000, 1000]])\n",
    "    tform = SimilarityTransform()\n",
    "    tform.estimate(src, dst)\n",
    "    kp[22:27, :] = tform(kp[22:27, :])\n",
    "    kp[42:48, :] = tform(kp[42:48, :]) \n",
    "\n",
    "    # Registering jawline\n",
    "    src = kp[[0,16], :]\n",
    "    dst = np.float32([[300, 1000], [1100, 1000]])\n",
    "    tform = SimilarityTransform()\n",
    "    tform.estimate(src, dst)\n",
    "    kp[0:17, :] = tform(kp[0:17, :])\n",
    "    \n",
    "    # Registering nose\n",
    "    delta_x = 700 - kp[27, 0] \n",
    "    delta_y = 1000 - kp[27, 1]\n",
    "    kp[27:36, 0], kp[27:36, 1] =  kp[27:36, 0]+delta_x, kp[27:36, 1]+delta_y\n",
    "    \n",
    "    return np.array(matrix), kp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_kp=68 # For any data, since all are vectorized to 68 keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Dataset', 'Subject_id', 'Video_id', 'Offset_Frame', 'Apex_Frame']\n",
    "\n",
    "for i in range(n_kp):\n",
    "  columns.append(\"Offset_x\"+str(i))\n",
    "  columns.append(\"Offset_y\"+str(i))\n",
    "    \n",
    "for i in range(n_kp):\n",
    "  columns.append(\"Apex_x\"+str(i))\n",
    "  columns.append(\"Apex_y\"+str(i))\n",
    "    \n",
    "for i in range(n_kp):\n",
    "  columns.append(\"Offset_x\"+str(i)+\"_Normalized\")\n",
    "  columns.append(\"Offset_y\"+str(i)+\"_Normalized\")\n",
    "    \n",
    "for i in range(n_kp):\n",
    "  columns.append(\"Apex_x\"+str(i)+\"_Normalized\")\n",
    "  columns.append(\"Apex_y\"+str(i)+\"_Normalized\")\n",
    "\n",
    "for i in range(9):\n",
    "    columns.append(\"offset_a\"+str(i))\n",
    "    \n",
    "for i in range(9):\n",
    "    columns.append(\"apex_a\"+str(i))\n",
    "\n",
    "for i in range(100):\n",
    "  columns.append(\"AU\"+str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "667"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.DataFrame(columns = columns).columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRpYelXwxYsr"
   },
   "source": [
    "# DISFA keypoint dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FacialLandmarkFrontalization_66.source.utils import frontalize_landmarks\n",
    "wts = np.load(\"FacialLandmarkFrontalization_66/data/frontalization_weights.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X82uMHUHyeNL",
    "outputId": "f2aef8d6-a1d0-422e-d63c-b66bfa530543"
   },
   "outputs": [],
   "source": [
    "gt_output_path =  \"../../datasets/macro/Spontaneous/DISFA/DISFA/Landmark_Points/\"\n",
    "au_coding_path = \"../../datasets/macro/Spontaneous/DISFA/DISFA/ActionUnit_Labels/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_path_list = glob.glob(\"/mnt/data/StrokeML/Macroexpression/DISFA/DISFA/Frames_LeftCamera/*/\", recursive=True)\n",
    "kp_path_list = glob.glob(au_coding_path+\"../Landmark_Points/*/\", recursive=True)\n",
    "frame_path_list.sort()\n",
    "kp_path_list.sort()\n",
    "count = 0\n",
    "\n",
    "for frame_path, kp_path in zip(frame_path_list, kp_path_list):\n",
    "#     print(frame_path)\n",
    "    jpg_list = glob.glob(frame_path+\"**/*.jpg\", recursive=True)\n",
    "    kp_list = glob.glob(kp_path+\"**/*.mat\", recursive=True)\n",
    "\n",
    "    jpg_list.sort()\n",
    "    kp_list.sort()\n",
    "    if len(jpg_list)!=len(kp_list):\n",
    "        print(frame_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_sub_left = [4, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_neutral_frame = 3741"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating pair list for all frames for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_pt_path = \"../../datasets/macro/Spontaneous/DISFA/DISFA/Landmark_Points/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_list_all_frames = []\n",
    "sub_no_list = []\n",
    "for sub in glob.glob(landmark_pt_path+\"*/*/\", recursive=True):\n",
    "    sub_split = sub.split(\"/\")\n",
    "    sub_no = int(sub_split[-3][3:5])\n",
    "    sub_no_list.append(sub_no)\n",
    "    print(\"Subject No : \", sub_no)\n",
    "    offset = global_neutral_frame \n",
    "\n",
    "    for apex in range(len(os.listdir(sub))):\n",
    "        if apex!=global_neutral_frame:\n",
    "            pair = [0, sub_no, offset, apex, 0]\n",
    "            pair_list_all_frames.append(pair)\n",
    "\n",
    "print(\"Total frames : \", len(pair_list_all_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GKOIBwTpmKyl"
   },
   "outputs": [],
   "source": [
    "sub_no_list = list(pd.DataFrame(sub_no_list)[0].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_no_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_no_left = list(set(sub_no_list) - set(ignore_sub_left))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fBn3vzZ5xWVP"
   },
   "outputs": [],
   "source": [
    "kp_l = []\n",
    "\n",
    "for sub in sub_no_left:\n",
    "    mat_path = gt_output_path+\"SN0\"+f\"{sub:02}\"+\"/\"\n",
    "#     print(mat_path)\n",
    "    kp_list = glob.glob(mat_path+\"*/*.mat\", recursive=True)\n",
    "    kp_list.sort()\n",
    "    \n",
    "    video = np.zeros((len(kp_list), 66, 2))\n",
    "    for i in range(len(kp_list)):\n",
    "        mat = scipy.io.loadmat(kp_list[i])\n",
    "        video[i, :, :] = mat['pts']\n",
    "    \n",
    "    kp_l.append(video) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disfa_66_to_68(kp):\n",
    "    kp_new = np.zeros((68, 2))\n",
    "    kp_new[:60, :] = kp[:60, :]\n",
    "    kp_new[61:64, :] = kp[60:63, :]\n",
    "    kp_new[65:68, :] = kp[63:66, :]\n",
    "    return kp_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uVjM6JufonNh"
   },
   "outputs": [],
   "source": [
    "def create_final_data(pair_list):\n",
    "# \n",
    "    au_list = list([1,2,4,5,6,9,12,15,17,20,25,26])\n",
    "\n",
    "    index_list = [0, 16, 27, 33, 39, 42, 36, 45]\n",
    "    X_ori = np.float32([[300,900], [1100, 900], [700, 915], [700, 1300],[600,920],[800,920], [400, 910], [1000, 910]])\n",
    "\n",
    "\n",
    "    final_data = []\n",
    "\n",
    "    for key in pair_list:\n",
    "\n",
    "        try:\n",
    "            res2 = []\n",
    "            au_array = np.zeros(100)\n",
    "            res2.extend(('DISFA', \"LeftVideoSN0\"+f\"{key[1]:02}\", 'Videos_LeftCamera'))\n",
    "            video_l = kp_l[sub_no_left.index(key[1])]\n",
    "        \n",
    "            offset = video_l[key[2], :, :]\n",
    "            offset = frontalize_landmarks(offset, wts)\n",
    "            offset = 200*(offset+np.amax(offset))\n",
    "            offset_matrix, offset_n = affine_trans(offset)\n",
    "            _, offset_n = similarity_trans(offset_n)   \n",
    "            offset = disfa_66_to_68(offset)\n",
    "            offset_n = disfa_66_to_68(offset_n)\n",
    "\n",
    "            apex = video_l[key[3], :, :]\n",
    "            apex = frontalize_landmarks(apex, wts)\n",
    "            apex = 200*(apex+np.amax(apex))\n",
    "            apex_matrix, apex_n = affine_trans(apex)\n",
    "            _, apex_n = similarity_trans(apex_n)\n",
    "            apex = disfa_66_to_68(apex)\n",
    "            apex_n = disfa_66_to_68(apex_n)      \n",
    "\n",
    "            res2.extend(np.concatenate(([key[2]], [key[3]], offset.flatten(), apex.flatten(), offset_n.flatten(), apex_n.flatten(), offset_matrix.flatten(), apex_matrix.flatten(), au_array.flatten())))\n",
    "            final_data.append(res2)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mGA_J7h5LTwI"
   },
   "outputs": [],
   "source": [
    "final_data_all_frames = create_final_data(pair_list_all_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_disfa = pd.DataFrame(final_data, columns=columns)\n",
    "# cols_groupby = columns[:-100]\n",
    "# cols_au = columns[-100:]\n",
    "# df_temp = df_disfa.copy()\n",
    "# df_temp = df_temp.groupby(cols_groupby)[cols_au].sum().reset_index()\n",
    "# df_temp.to_csv(\"Data/reg1_6_pts/cum_event_front_facing_2level_reg_eyes_eyebrows_jawline_nose/left_DISFA_GlobalNeutral.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(final_data_all_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_data_all_frames) #121099"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disfa = pd.DataFrame(final_data_all_frames, columns=columns)\n",
    "cols_groupby = columns[:-100]\n",
    "cols_au = columns[-100:]\n",
    "df_temp = df_disfa.copy()\n",
    "df_temp = df_temp.groupby(cols_groupby)[cols_au].sum().reset_index()\n",
    "# df_temp.to_csv(\"Data/reg1_6_pts/cum_event_front_facing_2level_reg_eyes_eyebrows_jawline_nose/left_DISFA_GlobalNeutral_all_frames_8p.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminating frames from Error_LOG_Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp = pd.read_csv(\"Data/reg1_6_pts/cum_event_front_facing_2level_reg_eyes_eyebrows_jawline_nose/left_DISFA_GlobalNeutral_all_frames_8p.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_sheet_path = \"../../datasets/macro/Spontaneous/DISFA/DISFA/Error_LOG_Sheet.xls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error = pd.read_excel(error_sheet_path, sheet_name=\"Sheet1\", ).iloc[5:19, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp_copy = df_temp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp_copy.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp = df_temp_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df_error.shape[0]-1):\n",
    "    df_error_sub = df_error.iloc[i, :].dropna()\n",
    "    print(df_error_sub)\n",
    "    if df_error_sub[0]==\"SN011\":\n",
    "        df_error_sub = df_error_sub[:-1]\n",
    "    subject_name = \"LeftVideo\"+df_error_sub[0]\n",
    "    print(subject_name)\n",
    "    error_frames = np.array(df_error_sub[1:]).reshape(-1, 2)\n",
    "    for start_error_frame, end_error_frame in zip(error_frames[:, 0], error_frames[:, 1]):        \n",
    "        df_temp.drop(df_temp[(df_temp[\"Subject_id\"]==subject_name) & (df_temp[\"Offset_Frame\"]>=start_error_frame) & (df_temp[\"Offset_Frame\"]<=end_error_frame)].index, inplace=True)\n",
    "        df_temp.drop(df_temp[(df_temp[\"Subject_id\"]==subject_name) & (df_temp[\"Apex_Frame\"]>=start_error_frame) & (df_temp[\"Apex_Frame\"]<=end_error_frame)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.to_csv(\"Data/DISFA_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_temp.shape) #114654"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_temp.sample(frac=1, random_state=17).iloc[:10100, :]\n",
    "df_temp.reset_index(inplace=True)\n",
    "df_temp.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.to_csv(\"Data/DISFA_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BP4D-Spontaneous keypoint dataset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating csv for intensity coded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "au_coding_path = \"../../datasets/macro/Spontaneous/BP4D_Spontaneous/AUCoding/AU_INT/\"\n",
    "au_coding_new_path = \"../../datasets/macro/Spontaneous/BP4D_Spontaneous/AUCoding_new/AU_INT/\"\n",
    "# alpha_path = \"../../project/Face_Tracking/alphapose/outputs/BP4D_Spontaneous/\"\n",
    "img_path = \"/mnt/scratch2/csy207576/project/datasets/macro/Spontaneous/BP4D_Spontaneous/Sequences(2D+3D)/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "csv = 0\n",
    "for csv_path in glob.glob(au_coding_path+\"*/*.csv\", recursive=True):\n",
    "    csv += 1\n",
    "    \n",
    "    au_coding = pd.read_csv(csv_path, header=None)\n",
    "#     print(au_coding)\n",
    "    length = au_coding[0][au_coding.shape[0]-1] - au_coding[0][0] + 1\n",
    "#     print(csv_path, length)\n",
    "    if length==au_coding.shape[0]:\n",
    "        count+=1\n",
    "print(count, csv)\n",
    "\n",
    "# The above shows that the frame numbers are consistent without any gaps from start to end in csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore_json_list = []\n",
    "# ori_count = 0\n",
    "# check_count = 0\n",
    "\n",
    "# for txt_path in glob.glob(au_coding_path+\"*/*.csv\", recursive=True):\n",
    "#     ori_count += 1\n",
    "#     sub_id = txt_path.split(\"/\")[-1][:4]\n",
    "#     video_id = txt_path.split(\"/\")[-1][5:7]\n",
    "    \n",
    "#     img = img_path+sub_id+\"/\"+sub_id+\"/\"+video_id+\"/*.jpg\"\n",
    "#     img_length = len(glob.glob(img_path+sub_id+\"/\"+sub_id+\"/\"+video_id+\"/*.jpg\", recursive=True))\n",
    "\n",
    "#     json_path = alpha_path + sub_id + \"/\" + video_id + \"/\" + \"alphapose-results.json\"\n",
    "    \n",
    "#     json_length = len(json.load(open(json_path)))\n",
    "\n",
    "#     if img_length==json_length:\n",
    "#         check_count += 1\n",
    "#     else:\n",
    "#         ignore_json_list.append(txt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ori_count, check_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.arange(1, img_length+1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating new AU Files that are similar to DISFA+ coding\n",
    "\n",
    "# for csv_path in glob.glob(au_coding_path+\"*/*.csv\", recursive=True):\n",
    "#     print(csv_path)\n",
    "#     sub_id = csv_path.split(\"/\")[-1][:4]\n",
    "#     video_id = csv_path.split(\"/\")[-1][5:7]\n",
    "    \n",
    "#     temp_img_path = img_path+sub_id+\"/\"+sub_id+\"/\"+video_id+\"/*.jpg\"\n",
    "#     img_length = len(glob.glob(temp_img_path, recursive=True))\n",
    "\n",
    "#     au_new = np.zeros((img_length, 2))\n",
    "#     au_coding = pd.read_csv(csv_path, header=None)\n",
    "    \n",
    "#     start = au_coding.iloc[0, 0]\n",
    "#     end = start + au_coding.shape[0] - 1\n",
    "\n",
    "#     au_new[:, 0] = np.arange(1, img_length+1, 1)\n",
    "\n",
    "#     au_new[(start-1):end, 1] = np.array(au_coding.iloc[:, 1])\n",
    "    \n",
    "#     new_au_path = au_coding_new_path +csv_path.split(\"/\")[-2]+\"/\"+csv_path.split(\"/\")[-1][:-4]+\".txt\"\n",
    "    \n",
    "#     au_new = np.array(au_new, dtype=np.int64)\n",
    "#     np.savetxt(new_au_path, au_new, delimiter=' ', newline='\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_list = []\n",
    "for i in range(1, 24):\n",
    "    sub_list.append(\"F\"+str(i).zfill(3))\n",
    "for i in range(1, 19):\n",
    "    sub_list.append(\"M\"+str(i).zfill(3))\n",
    "    \n",
    "print(sub_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FacialLandmarkFrontalization_49.source.utils import frontalize_landmarks\n",
    "wts = np.load(\"FacialLandmarkFrontalization_49/data/frontalization_weights.npy\")\n",
    "\n",
    "\n",
    "def kp_preprocess_bp4d(kp):\n",
    "    kp_temp = np.zeros((66,2))\n",
    "    kp_temp[17:, :] = kp\n",
    "    kp_temp = disfa_66_to_68(kp_temp)\n",
    "    kp_temp[:17, :] = np.zeros((17, 2))\n",
    "    return kp_temp\n",
    "\n",
    "\n",
    "def kp_preprocess_bp4d_n(kp):\n",
    "    kp_temp = kp.copy()\n",
    "    kp_temp[:, 0] = kp_temp[:, 0] - np.amin(kp_temp[:, 0]) + 50\n",
    "    kp_temp[:, 1] = kp_temp[:, 1] - np.amin(kp_temp[:, 1]) + 50\n",
    "\n",
    "    kp_temp = kp_preprocess_bp4d(kp_temp)\n",
    "    kp_temp = frontalize_landmarks(kp_temp, wts)\n",
    "    kp_temp += np.amax(kp_temp)\n",
    "    kp_temp = 200*kp_temp\n",
    "    matrix, kp_temp = affine_trans(kp_temp, \"bp4d\")\n",
    "    _, kp_temp = similarity_trans(kp_temp)\n",
    "    kp_temp[:17, :] = np.zeros((17, 2))\n",
    "    kp_temp[60, :] = [0,0]\n",
    "    kp_temp[64, :] = [0,0]\n",
    "    return matrix, kp_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing the Offset frames per subject\n",
    "import glob\n",
    "import itertools\n",
    "au_csv_path = \"../../datasets/macro/Spontaneous/BP4D_Spontaneous/AUCoding/AU_OCC/\"\n",
    "kp_path = \"../../datasets/macro/Spontaneous/BP4D_Spontaneous/2DFeatures_temp/\"\n",
    "global_min_list = []\n",
    "pair_list = []\n",
    "final_data = []\n",
    "count = 0\n",
    "\n",
    "for sub in sub_list:\n",
    "    count+=1\n",
    "    apex_list = []\n",
    "    min_list = [\"\", \"\", -10, -10000, 10000] # sub, vid, min_index, freq\n",
    "    for au_csv in glob.glob(au_csv_path+sub+\"*.csv\", recursive=True):\n",
    "        \n",
    "        vid_id = au_csv[-6:-4]\n",
    "        df_csv = pd.read_csv(au_csv)\n",
    "        df_csv.replace(9, 0, inplace=True)\n",
    "        df_sum = df_csv.iloc[:, 1:].sum(axis=1)\n",
    "        \n",
    "        \n",
    "        for t in range(df_sum.shape[0]):\n",
    "            if df_sum.iloc[t]>0:\n",
    "                apex_frame = df_csv.iloc[t, 0]\n",
    "                try:\n",
    "                    apex = np.loadtxt(kp_path+sub+\"/\"+sub+\"/\"+vid_id+\"/\"+str(apex_frame).zfill(4)+\".txt\", delimiter=\",\")\n",
    "                    apex_list.append([apex_frame, apex, sub, vid_id])\n",
    "                except:\n",
    "                    apex = np.loadtxt(kp_path+sub+\"/\"+sub+\"/\"+vid_id+\"/\"+str(apex_frame).zfill(3)+\".txt\", delimiter=\",\")\n",
    "                    apex_list.append([apex_frame, apex, sub, vid_id])\n",
    "        \n",
    "        \n",
    "        df_sum = df_sum.to_numpy()\n",
    "        arr = np.zeros(df_sum.shape[0])\n",
    "        indices = np.where(df_sum==np.amin(df_sum))\n",
    "        arr[indices] = 1\n",
    "        freq = [(k, len(list(j))) for k, j in groupby(list(arr))]\n",
    "        max_ind = -10\n",
    "        for k in range(len(freq)):\n",
    "            if freq[k][0] == 0:\n",
    "                continue\n",
    "            else:\n",
    "                if max_ind == -10:\n",
    "                    max_ind = k\n",
    "                elif freq[k][1]> freq[max_ind][1]:\n",
    "                    max_ind = k\n",
    "        freq = np.array(freq)\n",
    "        max_index_csv = int(np.sum(freq[:max_ind, 1]) + np.sum(freq[max_ind, 1])//2)\n",
    "        \n",
    "        if min_list[4]>np.amin(df_sum):\n",
    "            min_list = [sub, vid_id, df_csv.iloc[max_index_csv,0], freq[max_ind, 1], np.amin(df_sum)]\n",
    "        elif min_list[4]==np.amin(df_sum):\n",
    "            if min_list[3]<freq[max_ind, 1]:\n",
    "                min_list = [sub, vid_id, df_csv.iloc[max_index_csv,0], freq[max_ind, 1], np.amin(df_sum)]                \n",
    "        \n",
    "    print(min_list)\n",
    "        \n",
    "    sub = min_list[0]\n",
    "    vid_id = min_list[1]\n",
    "    offset_vid = vid_id\n",
    "    offset_frame = min_list[2]\n",
    "    try:\n",
    "        offset = np.loadtxt(kp_path+sub+\"/\"+sub+\"/\"+vid_id+\"/\"+str(offset_frame).zfill(4)+\".txt\", delimiter=\",\")\n",
    "    except:\n",
    "        offset = np.loadtxt(kp_path+sub+\"/\"+sub+\"/\"+vid_id+\"/\"+str(offset_frame).zfill(3)+\".txt\", delimiter=\",\")\n",
    "    \n",
    "    \n",
    "    offset_matrix, offset_n = kp_preprocess_bp4d_n(offset)\n",
    "    # the above code also changed values in offset since a reference is passed and not a copy\n",
    "    offset = kp_preprocess_bp4d(offset)\n",
    "    for apex_pair in apex_list:\n",
    "        \n",
    "        try:\n",
    "            apex = apex_pair[1]\n",
    "            sub = apex_pair[2]\n",
    "            vid_id = apex_pair[3]\n",
    "            apex_matrix, apex_n = kp_preprocess_bp4d_n(apex)\n",
    "            # the above code also changed values in offset since a reference is passed and not a copy\n",
    "            apex_frame = apex_pair[0]\n",
    "\n",
    "            apex = kp_preprocess_bp4d(apex)\n",
    "            res = []   \n",
    "            res.extend([\"BP4D_Spontaneous\", sub, offset_vid+\"_\"+vid_id, offset_frame, apex_frame])\n",
    "            res.extend(np.concatenate((offset.flatten(), apex.flatten(), offset_n.flatten(), apex_n.flatten(), offset_matrix.flatten(), apex_matrix.flatten(), np.zeros((100)))))\n",
    "            final_data.append(res)\n",
    "#         rows_count+=1\n",
    "#         if rows_count>=10:\n",
    "#             break\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "#     if rows_count>=10:\n",
    "#         break\n",
    "        \n",
    "    global_min_list.append(min_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bp4d = pd.DataFrame(final_data, columns=columns)\n",
    "cols_groupby = columns[:-100]\n",
    "cols_au = columns[-100:]\n",
    "df_temp = df_bp4d.copy()\n",
    "df_temp = df_temp.groupby(cols_groupby)[cols_au].sum().reset_index()\n",
    "df_temp.to_csv(\"Data/BP4D_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_temp.sample(frac=1, random_state=17).iloc[:10100, :]\n",
    "df_sample.reset_index(inplace=True)\n",
    "df_sample.drop(columns=['index'], inplace=True)\n",
    "df_sample.to_csv(\"Data/BP4D_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CK+ keypoint dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FacialLandmarkFrontalization.source.utils import frontalize_landmarks\n",
    "wts = np.load(\"FacialLandmarkFrontalization/data/frontalization_weights.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n",
      "tuple index out of range\n"
     ]
    }
   ],
   "source": [
    "gt_path = \"../../datasets/macro/Both/CK+/CK+/Landmarks/\"\n",
    "au_path = \"../../datasets/macro/Both/CK+/CK+/FACS/\"\n",
    "\n",
    "final_data_all_frames = []\n",
    "\n",
    "check_count = 0\n",
    "\n",
    "for kp_file_path in glob.glob(gt_path+\"*/*/\", recursive=True):\n",
    "    \n",
    "    video = os.listdir(kp_file_path)\n",
    "    video.sort()\n",
    "\n",
    "    sub_id = kp_file_path.split(\"/\")[-3]\n",
    "    video_id = kp_file_path.split(\"/\")[-2]\n",
    "    \n",
    "    au = np.loadtxt(open(glob.glob(au_path + sub_id +\"/\" + video_id + \"/*.txt\", recursive=True)[0]))\n",
    "    \n",
    "    au_array = np.zeros(100)\n",
    "    \n",
    "    try:\n",
    "        temp = au.shape[0]*au.shape[1]\n",
    "        for row in au:\n",
    "            au_array[int(row[0]) - 1] = row[1]\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        au_array[int(au[0]) - 1] = au[1]\n",
    "\n",
    "\n",
    "    offset_frame = 0\n",
    "    for apex_frame in range(1, len(video)):\n",
    "        \n",
    "        try:\n",
    "            offset = np.loadtxt(kp_file_path+video[0])\n",
    "            offset_n = frontalize_landmarks(offset, wts)\n",
    "    #         offset = 200*(offset+np.amax(offset))\n",
    "            offset_matrix, offset_n = affine_trans(offset_n)\n",
    "            _, offset_n = similarity_trans(offset_n)\n",
    "\n",
    "#             apex = np.loadtxt(kp_file_path+video[-1])\n",
    "            apex = np.loadtxt(kp_file_path+video[apex_frame])\n",
    "            apex_n = frontalize_landmarks(apex, wts)\n",
    "    #         apex = 200*(apex+np.amax(apex))\n",
    "            apex_matrix, apex_n = affine_trans(apex_n)\n",
    "            _, apex_n = similarity_trans(apex_n)\n",
    "            res = []\n",
    "            res.extend(['CK+', sub_id, video_id, offset_frame, apex_frame])\n",
    "\n",
    "            res.extend(np.concatenate((offset.flatten(), apex.flatten(), offset_n.flatten(), apex_n.flatten(), offset_matrix.flatten(), apex_matrix.flatten(), au_array.flatten())))\n",
    "            final_data_all_frames.append(res)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10100"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_data_all_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CK_plus = pd.DataFrame(final_data_all_frames, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CK_plus.to_csv(\"Data/CK+.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pure AUs keypoint dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FacialLandmarkFrontalization.source.utils import frontalize_landmarks\n",
    "wts = np.load(\"FacialLandmarkFrontalization/data/frontalization_weights.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 no doesn't exist\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s45.txt not found.\n",
      "46 no doesn't exist\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s46.txt not found.\n",
      "31 no doesn't exist\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s31.txt not found.\n",
      "38 no doesn't exist\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s38.txt not found.\n",
      "39 no doesn't exist\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s39.txt not found.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "au_kp_path = \"../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/\"\n",
    "apex_list = {'4b':[\"Brow Lowerer\",[17,27],[36,48]] ,'1':[\"Inner Brow Raiser\",[17,27]],'2':[\"Outer Brow Raiser\",[17,27],[36,48]],'5z':[\"Upper Lid Raiser\",[17,27],[36,48]],'7':[\"Lid Tightener\",[17,27],[36,48]],'6':[\"Cheek Raiser and Lid Compressor\",[17,68]],'43':[\"Eye Closure\",[36,48]],'45':[\"Blink\", [36,48]],'46':[\"Wink\",[36,48]],'9':[\"Nose Wrinkler\",[17,68]],'10x':[\"Upper Lip Raiser\",[27,36],[48,68]],'17':[\"Chin Raiser\",[0,17],[48,68]],'15x':[\"Lip Corner Depressor\",[48,68]],'25':[\"Lips Part\",[48,68]],'26':[\"Jaw Drop\",[0,17],[48,68]],'27':[\"Mouth Stretch\",[0,17],[48,68]],'16_25':[\"Lower Lip Depressor\",[0,17],[48,68]],'20x':[\"Lip Stretcher\",[0,17],[48,68]],'14':[\"Dimpler\",[0,17],[48,68]],'11':[\"Nasolabial Furrow Deepener\",[0,68]],'12x':[\"Lip Corner Puller\",[48,68]],'13b':[\"Sharp Lip Puller\",[48,68]],'18a':[\"Lip Pucker\",[48,68]],'22_25':[\"Lip Funneler\",[48,68]],'23':[\"Lip Tightener\",[48,68]],'24':[\"Lip Presser\",[48,68]],'28':[\"Lips Suck\",[48,68]],'21':[\"Neck Tightener\",[0,17]],'31':[\"Jaw Clencher\",[0,17]],'38':[\"Nostril Dilator\",[27,36]],'39':[\"Nostril Compressor\",[27,36]]}\n",
    "\n",
    "final_data = []\n",
    "\n",
    "offset = np.loadtxt(au_kp_path+\"s0.txt\")\n",
    "offset_n = frontalize_landmarks(offset, wts)\n",
    "offset_matrix, offset_n = affine_trans(offset_n)\n",
    "_, offset_n = similarity_trans(offset_n)\n",
    "\n",
    "for au in apex_list:\n",
    "    if not Path(au_kp_path+\"s\"+au+\".jpg\").exists():\n",
    "        print(au, \"no doesn't exist\")\n",
    "        \n",
    "    res = []\n",
    "    au_array = np.zeros(100)\n",
    "    \n",
    "    try:\n",
    "        apex = np.loadtxt(au_kp_path+\"s\"+au+\".txt\")\n",
    "        apex_n = frontalize_landmarks(apex, wts)\n",
    "        apex_matrix, apex_n = affine_trans(apex_n)\n",
    "        _, apex_n = similarity_trans(apex_n)\n",
    "        res.extend(['Pure AU', apex_list[au][0], \"NA\", \"0\", au])\n",
    "\n",
    "        res.extend(np.concatenate((offset.flatten(), apex.flatten(), offset_n.flatten(), apex_n.flatten(), offset_matrix.flatten(), apex_matrix.flatten(), au_array.flatten())))\n",
    "        final_data.append(res)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AUs = pd.DataFrame(final_data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AUs.to_csv(\"Data/pureAUs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUs with combination keypoint dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68, 2) (68, 2)\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s1.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s1012x25.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s1012y25.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s102x162.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s102y162.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s10x.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s10y.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s10y1625.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s10y1723.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s10y2325.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s10y_14.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s10y_15z.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s10y_17.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s10y_20.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s10z1517.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s10z_25.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s11.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s12x.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s12x1625.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s12x_23.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s12x_24.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s12x_26.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s12y_17.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s12y_24.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s12y_25.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s13_25.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s13a.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s13b.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s14.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s14_17.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s14_23.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s15x.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s15y_23.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s15z.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s15z_17.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s16_25.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s17.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s17_23.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s17_24.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s18_23.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s18_25.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s18a.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s18b.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s1_2.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s1_2_4a.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s1_2_4b.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s1_2_5x.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s1_2_5z.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s1_4a.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s1_4b.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s2.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s20x.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s20x2325.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s20x_25.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s20x_26.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s20x_27.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s20y_26.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s20z.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s20z2325.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s20z_27.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s21.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s22_2325.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s22_25.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s23.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s23_25.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s23_26.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s24.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s25.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s26.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s27.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s28.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s29.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s35.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s41.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s42.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s43.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s44.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s4_5x.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s4a.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s4b.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s5x.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s5y_7.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s5z.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s6.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s6121517.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s6122325.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s612x15x.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s612y151.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s612z15y.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s6_12x.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s6_12y15.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s6_12y17.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s6_12y23.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s6_12y24.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s6_12y25.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s6_12z.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s6_12z17.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s6_12z25.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s6_12z26.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s6_12z27.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s6_13a.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s6_13b.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s6_15x.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s6_15z.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s6_15z17.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s6_4.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s6_43.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s7.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s7_43.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s9.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s9_16_25.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s9_17.txt\n",
      "../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/s9_25.txt\n",
      "(113, 667)\n"
     ]
    }
   ],
   "source": [
    "au_kp_path = \"../../Face_Tracking/SRT/outputs/Ekman/Manual/Examples/\"\n",
    "apex_list = {'4b':[\"Brow Lowerer\",[17,27],[36,48]] ,'1':[\"Inner Brow Raiser\",[17,27]],'2':[\"Outer Brow Raiser\",[17,27],[36,48]],'5z':[\"Upper Lid Raiser\",[17,27],[36,48]],'7':[\"Lid Tightener\",[17,27],[36,48]],'6':[\"Cheek Raiser and Lid Compressor\",[17,68]],'43':[\"Eye Closure\",[36,48]],'45':[\"Blink\", [36,48]],'46':[\"Wink\",[36,48]],'9':[\"Nose Wrinkler\",[17,68]],'10x':[\"Upper Lip Raiser\",[27,36],[48,68]],'17':[\"Chin Raiser\",[0,17],[48,68]],'15x':[\"Lip Corner Depressor\",[48,68]],'25':[\"Lips Part\",[48,68]],'26':[\"Jaw Drop\",[0,17],[48,68]],'27':[\"Mouth Stretch\",[0,17],[48,68]],'16_25':[\"Lower Lip Depressor\",[0,17],[48,68]],'20x':[\"Lip Stretcher\",[0,17],[48,68]],'14':[\"Dimpler\",[0,17],[48,68]],'11':[\"Nasolabial Furrow Deepener\",[0,68]],'12x':[\"Lip Corner Puller\",[48,68]],'13b':[\"Sharp Lip Puller\",[48,68]],'18a':[\"Lip Pucker\",[48,68]],'22_25':[\"Lip Funneler\",[48,68]],'23':[\"Lip Tightener\",[48,68]],'24':[\"Lip Presser\",[48,68]],'28':[\"Lips Suck\",[48,68]],'21':[\"Neck Tightener\",[0,17]],'31':[\"Jaw Clencher\",[0,17]],'38':[\"Nostril Dilator\",[27,36]],'39':[\"Nostril Compressor\",[27,36]]}\n",
    "neutral = ['0']\n",
    "\n",
    "final_data = []\n",
    "\n",
    "offset = np.loadtxt(au_kp_path+\"s0.txt\")\n",
    "offset_n = frontalize_landmarks(offset, wts)\n",
    "offset_matrix, offset_n = affine_trans(offset_n)\n",
    "_, offset_n = similarity_trans(offset_n)\n",
    "print(offset.shape, offset_n.shape)\n",
    "offset_n_ori = offset_n\n",
    "\n",
    "\n",
    "for apex_path in glob.glob(au_kp_path+\"*.txt\"):\n",
    "    \n",
    "    temp = apex_path.split(\"/\")[-1]\n",
    "    if \"s0.txt\" in temp or \"sJ\" in temp or \"sL\" in temp or \"sW\" in temp: \n",
    "        continue\n",
    "    print(apex_path)\n",
    "    res = []\n",
    "    au_array = np.zeros(100)\n",
    "    \n",
    "#     try:\n",
    "    apex = np.loadtxt(apex_path)\n",
    "    apex_n = frontalize_landmarks(apex, wts)\n",
    "    apex_matrix, apex_n = affine_trans(apex_n)\n",
    "    _, apex_n = similarity_trans(apex_n)\n",
    "    res.extend(['AU_with_combinations', \"NA\", \"NA\", \"0\", temp[:-4]])\n",
    "\n",
    "    res.extend(np.concatenate((offset.flatten(), apex.flatten(), offset_n.flatten(), apex_n.flatten(), offset_matrix.flatten(), apex_matrix.flatten(), au_array.flatten())))\n",
    "    final_data.append(res)\n",
    "#     except Exception as e:\n",
    "#         print(str(e))\n",
    "#         pass\n",
    "    \n",
    "    \n",
    "df_AUs = pd.DataFrame(final_data, columns=columns)\n",
    "print(df_AUs.shape)\n",
    "df_AUs.to_csv(\"Data/combAUs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation features for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = DataLoader()\n",
    "\n",
    "# for data_name in [\"DISFA_train\", \"DISFA_full\", \"BP4D_train\", \"BP4D_full\", \"CK+\", \"pureAUs\", \"combAUs\"]:\n",
    "for data_name in [\"pureAUs\",\"combAUs\"]:\n",
    "    df, _, cols_n = d.delta_loader(\"Data/\"+data_name+\".csv\")\n",
    "    X = df[cols_n[0]+cols_n[1]]\n",
    "    X = X.to_numpy()\n",
    "    if \"pureAUs\" in data_name or \"combAUs\" in data_name:\n",
    "        X = X/np.linalg.norm(X, axis=1).reshape(X.shape[0], -1)\n",
    "    pd.DataFrame(X).to_csv(\"Data/delta_\"+data_name+\".csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "AU_Data_Creation",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
